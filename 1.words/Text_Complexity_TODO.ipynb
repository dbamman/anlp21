{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89dd4ae7",
   "metadata": {},
   "source": [
    "Common measures of textual complexity are derived from simple counts of words, sentences and syllables.  In this homework, you'll implement two of them: type-token ratio (a measure of vocabulary richness) and the [Flesch-Kincaid Grade Level](https://en.wikipedia.org/wiki/Flesch窶適incaid_readability_tests#Flesch窶適incaid_grade_level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4944f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't downloaded the sentence segmentation model before, do so here\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7820e",
   "metadata": {},
   "source": [
    "Q1: Find two different texts you'd like to compare (from any source).  For potential sources, see the [The American Presidency Project](https://www.presidency.ucsb.edu/documents/presidential-documents-archive-guidebook/annual-messages-congress-the-state-the-union) for all state of the union addresses and [Project Gutenberg](https://www.gutenberg.org) for books in the public domain.  Paste them in the `text1` and `text2` strings below.  Ensure that both texts are a minimum of 500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d080408",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=\"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020c0bd",
   "metadata": {},
   "source": [
    "Q2: Use the `nltk.word_tokenize` method to implement the type-token ratio:\n",
    "\n",
    "$$\n",
    "TTR = {\\textrm{number of distinct word types} \\over \\textrm{number of word tokens}}\n",
    "$$\n",
    "\n",
    "TTR is dependent on text length (intuitively, the longer a text is, the greater chance you have of a word type repeating), so this number is only comparable between documents of identical lengths.  Calculate this measure for the first 500 words of your two documents and report the results here. Exclude tokens that are exclusively punctuation from all counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(text, num_words=500):\n",
    "    # your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_token_ratio(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_token_ratio(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec573a",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554c8c5",
   "metadata": {},
   "source": [
    "Now we'll implement the [Flesch-Kincaid Grade Level](https://en.wikipedia.org/wiki/Flesch窶適incaid_readability_tests#Flesch窶適incaid_grade_level), which has the following formula:\n",
    "\n",
    "$$\n",
    "0.39 \\left ( \\frac{\\mbox{total words}}{\\mbox{total sentences}} \\right ) + 11.8 \\left ( \\frac{\\mbox{total syllables}}{\\mbox{total words}} \\right ) - 15.59\n",
    "$$\n",
    "\n",
    "Use `nltk.sent_tokenize` or spacy's `sents` function for counting the number of sentences, any word tokenization method we've covered for counting the number of words, and the `get_syllable_count` function below for counting the number of syllables in a word.  Exclude tokens that are exclusively punctuation from word and syllable counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b2be7",
   "metadata": {},
   "source": [
    "For calculating the syllables, we're going to use a number of resources: the [CMU pronunciation dictionary](https://github.com/cmusphinx/cmudict), which lists the ARPABET pronunciation for a list of words, along with [g2p](https://github.com/Kyubyong/g2p), a neural model trained to predict the pronunciation for words (which we can use for words not in the CMU dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e404cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install g2p_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5eea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p\n",
    "g2p = G2p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pronunciation(word):\n",
    "    if word in arpabet:\n",
    "        # pick the first pronunciation\n",
    "        return arpabet[word][0]\n",
    "\n",
    "    else:\n",
    "        return g2p(word)\n",
    "\n",
    "def get_syllable_count(word):\n",
    "    pronunciation=get_pronunciation(word)\n",
    "    sylls=0\n",
    "    for phon in pronunciation:\n",
    "        # vowels in arpabet end in digits (indicating stress)\n",
    "        if re.search(\"\\d$\", phon) is not None:\n",
    "            sylls+=1\n",
    "    return sylls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_syllable_count(\"Bamman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adfab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_syllable_count(\"27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8ed59",
   "metadata": {},
   "source": [
    "Q3. Implement Flesch-Kincaid Grade Level and report its results for your two texts.  Flesch-Kincaid relies on an implicit definition of a \"word\" and a \"sentence\", and different definitions will yield different grade level estimates. (In the problem definition above, we've already ruled out punctuation as constituing stand-alone words, and other assumptions lurk with every tokenization method). State your assumptions for the definition of \"word\" you have implemented and why they are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_kincaid_grade_level(text):\n",
    "    # your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be 11.265\n",
    "flesch_kincaid_grade_level(\"The Australian platypus is seemingly a hybrid of a mammal and reptilian creature\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04718a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_kincaid_grade_level(text1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_kincaid_grade_level(text2.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6db12",
   "metadata": {},
   "source": [
    "**Q3 \"word\" assumptions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5cf93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
